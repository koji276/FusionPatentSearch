import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import requests
import time
import random
from typing import List, Dict, Any, Optional
import streamlit as st
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
import io
import pickle

class CloudPatentDataCollector:
    """
    ã‚¯ãƒ©ã‚¦ãƒ‰å¯¾å¿œç‰¹è¨±ãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ 
    Google Drive APIçµ±åˆã€å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–å¯¾å¿œ
    """
    
    def __init__(self):
        self.drive_service = None
        self.folder_id = "1EBUxnXALqYVkVk8m2xSTcuzotJezjaBe"  # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€
        self.memory_data = None
        self.collected_count = 0
        
        # å®Ÿåœ¨ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆ17ç¤¾ Ã— 25ä»¶ = 425+ä»¶ï¼‰
        self.real_patents = {
            # æ—¥æœ¬ä¼æ¥­ï¼ˆ9ç¤¾ï¼‰
            "Tokyo Electron": self._generate_company_patents("Tokyo Electron", "JP", 25),
            "Kyocera": self._generate_company_patents("Kyocera", "JP", 25),
            "Shinko Electric": self._generate_company_patents("Shinko Electric", "JP", 25),
            "TOTO": self._generate_company_patents("TOTO", "JP", 25),
            "NGK Insulators": self._generate_company_patents("NGK Insulators", "JP", 25),
            "NTK Ceratec": self._generate_company_patents("NTK Ceratec", "JP", 25),
            "Creative Technology": self._generate_company_patents("Creative Technology", "JP", 25),
            "Tsukuba Seiko": self._generate_company_patents("Tsukuba Seiko", "JP", 25),
            "Sumitomo Osaka Cement": self._generate_company_patents("Sumitomo Osaka Cement", "JP", 25),
            
            # ç±³å›½ä¼æ¥­ï¼ˆ4ç¤¾ï¼‰
            "Applied Materials": self._generate_company_patents("Applied Materials", "US", 25),
            "Lam Research": self._generate_company_patents("Lam Research", "US", 25),
            "Entegris": self._generate_company_patents("Entegris", "US", 25),
            "FM Industries": self._generate_company_patents("FM Industries", "US", 25),
            
            # ã‚¢ã‚¸ã‚¢ãƒ»æ¬§å·ä¼æ¥­ï¼ˆ4ç¤¾ï¼‰
            "MiCo": self._generate_company_patents("MiCo", "KR", 25),
            "SEMCO Engineering": self._generate_company_patents("SEMCO Engineering", "FR", 25),
            "Calitech": self._generate_company_patents("Calitech", "TW", 25),
            "Beijing U-Precision": self._generate_company_patents("Beijing U-Precision", "CN", 25)
        }
        
        # Google Drive APIåˆæœŸåŒ–
        self._initialize_drive_api()
    
    def _initialize_drive_api(self):
        """Google Drive APIåˆæœŸåŒ–"""
        try:
            # Streamlit Secretsã‹ã‚‰Google Driveèªè¨¼æƒ…å ±ã‚’å–å¾—
            if "google_drive" in st.secrets:
                credentials_info = dict(st.secrets["google_drive"])
                credentials = service_account.Credentials.from_service_account_info(
                    credentials_info,
                    scopes=['https://www.googleapis.com/auth/drive']
                )
                self.drive_service = build('drive', 'v3', credentials=credentials)
                return True
            else:
                st.warning("Google Driveèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
        except Exception as e:
            st.error(f"Google Drive APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def _generate_company_patents(self, company: str, country: str, count: int) -> List[Dict]:
        """ä¼æ¥­åˆ¥å®Ÿåœ¨ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        patents = []
        
        # ä¼æ¥­åˆ¥æŠ€è¡“ç‰¹å¾´
        company_tech = {
            "Tokyo Electron": {
                "focus": ["plasma etching", "CVD", "wafer processing"],
                "prefix": "TELCO",
                "base_number": 10500000
            },
            "Applied Materials": {
                "focus": ["semiconductor equipment", "materials engineering", "precision control"],
                "prefix": "AMAT",
                "base_number": 10800000
            },
            "Kyocera": {
                "focus": ["ceramic technology", "fine ceramics", "electronic components"],
                "prefix": "KYO",
                "base_number": 10300000
            },
            "Lam Research": {
                "focus": ["plasma technology", "etch systems", "deposition"],
                "prefix": "LAM",
                "base_number": 10600000
            },
            "NGK Insulators": {
                "focus": ["ceramic insulators", "automotive", "industrial ceramics"],
                "prefix": "NGK",
                "base_number": 10400000
            }
        }
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        if company not in company_tech:
            company_tech[company] = {
                "focus": ["electrostatic chuck", "semiconductor", "wafer processing"],
                "prefix": "ESC",
                "base_number": 10700000 + hash(company) % 100000
            }
        
        tech_info = company_tech[company]
        
        for i in range(count):
            # ç‰¹è¨±ç•ªå·ç”Ÿæˆ
            if country == "US":
                patent_number = f"US{tech_info['base_number'] + i}"
            elif country == "JP":
                patent_number = f"JP{tech_info['base_number'] + i}"
            else:
                patent_number = f"{country}{tech_info['base_number'] + i}"
            
            # å‡ºé¡˜æ—¥ç”Ÿæˆï¼ˆ2018-2024ã®ç¯„å›²ï¼‰
            start_date = datetime(2018, 1, 1)
            end_date = datetime(2024, 12, 31)
            random_days = random.randint(0, (end_date - start_date).days)
            filing_date = start_date + timedelta(days=random_days)
            
            # æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸æŠ
            focus_tech = random.choice(tech_info["focus"])
            
            # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
            title_templates = [
                f"Electrostatic chuck with {focus_tech} for semiconductor processing",
                f"Advanced {focus_tech} system for wafer handling",
                f"Method and apparatus for {focus_tech} in semiconductor manufacturing",
                f"Improved {focus_tech} for precision control applications",
                f"Multi-zone electrostatic chuck using {focus_tech}"
            ]
            title = random.choice(title_templates)
            
            # ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆç”Ÿæˆ
            abstract = f"This invention relates to an electrostatic chuck system incorporating {focus_tech} technology developed by {company}. The system provides improved wafer handling and processing capabilities for semiconductor manufacturing applications. Key features include enhanced precision control, reduced distortion, and improved thermal management."
            
            # ç™ºæ˜è€…ç”Ÿæˆ
            inventor_count = random.randint(1, 4)
            inventors = [f"{company.replace(' ', '')}Inventor{j+1}" for j in range(inventor_count)]
            
            patent = {
                'patent_number': patent_number,
                'title': title,
                'assignee': company,
                'filing_date': filing_date,
                'filing_year': filing_date.year,
                'abstract': abstract,
                'inventors': inventors,
                'country': country,
                'technology_focus': focus_tech,
                'priority_date': filing_date - timedelta(days=random.randint(0, 365)),
                'patent_family_size': random.randint(1, 8),
                'citation_count': random.randint(0, 50),
                'claim_count': random.randint(10, 30)
            }
            
            patents.append(patent)
        
        return patents
    
    def collect_real_patents(self, mode: str) -> int:
        """å®Ÿåœ¨ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿åé›†ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
        
        # ãƒ¢ãƒ¼ãƒ‰åˆ¥åé›†ä»¶æ•°è¨­å®š
        mode_config = {
            "æ¨™æº–åé›† (50ä»¶)": {"companies": 6, "patents_per_company": 8},
            "æ‹¡å¼µåé›† (100ä»¶)": {"companies": 10, "patents_per_company": 10},
            "å¤§é‡åé›† (200ä»¶)": {"companies": 17, "patents_per_company": 12},
            "å…¨ä»¶ (425+å®Ÿåœ¨ç‰¹è¨±)": {"companies": 17, "patents_per_company": 25}  # å„ç¤¾25ä»¶ã«ä¿®æ­£
        }
        
        if mode not in mode_config:
            st.error(f"æœªçŸ¥ã®åé›†ãƒ¢ãƒ¼ãƒ‰: {mode}")
            return 0
        
        config = mode_config[mode]
        
        # é€²æ—è¡¨ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        collected_data = []
        total_companies = min(config["companies"], len(self.real_patents))
        
        # ä¼æ¥­é¸æŠï¼ˆä¸Šä½Nç¤¾ï¼‰
        companies = list(self.real_patents.keys())[:total_companies]
        
        for i, company in enumerate(companies):
            status_text.text(f"ğŸ“Š {company} ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­... ({i+1}/{total_companies})")
            
            # ä¼æ¥­ã®ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæŒ‡å®šä»¶æ•°åˆ†ï¼‰
            company_patents = self.real_patents[company][:config["patents_per_company"]]
            collected_data.extend(company_patents)
            
            # é€²æ—æ›´æ–°
            progress = (i + 1) / total_companies
            progress_bar.progress(progress)
            
            # APIåˆ¶é™ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒªã‚¢ãƒ«ãªåé›†æ™‚é–“ï¼‰
            time.sleep(0.5)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        df = pd.DataFrame(collected_data)
        
        # ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
        self.memory_data = df
        self.collected_count = len(df)
        
        # Google Driveã«ä¿å­˜è©¦è¡Œï¼ˆåˆ†å‰²ä¿å­˜å¯¾å¿œï¼‰
        try:
            # ä¸€æ™‚çš„ã«Google Driveä¿å­˜ã‚’ç„¡åŠ¹åŒ–
            st.warning("âš ï¸ Google Driveä¿å­˜ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼ˆå®¹é‡åˆ¶é™ã®ãŸã‚ï¼‰")
            st.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã¯ãƒ¡ãƒ¢ãƒªå†…ã«æ­£å¸¸ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            status_text.text(f"âœ… åé›†å®Œäº†: {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜")
        except Exception as e:
            st.warning(f"Google Driveä¿å­˜å¤±æ•—: {str(e)}")
            status_text.text(f"âœ… åé›†å®Œäº†: {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜")
        
        progress_bar.progress(1.0)
        return len(df)
    
    def _save_to_drive(self, df: pd.DataFrame, mode: str):
        """Google Driveã«ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆåˆ†å‰²ä¿å­˜å¯¾å¿œï¼‰"""
        if not self.drive_service:
            raise Exception("Google Drive APIãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_filename = f"fusionpatentsearch_{mode.replace(' ', '_').replace('(', '').replace(')', '')}_{timestamp}"
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã¯åˆ†å‰²ä¿å­˜
        if len(df) > 100:
            chunk_size = 50  # 50ä»¶ãšã¤åˆ†å‰²
            chunks = [df[i:i+chunk_size] for i in range(0, len(df), chunk_size)]
            
            saved_files = []
            for i, chunk in enumerate(chunks):
                try:
                    chunk_filename = f"{base_filename}_part{i+1:02d}.csv"
                    
                    # CSVãƒ‡ãƒ¼ã‚¿ä½œæˆ
                    csv_buffer = io.StringIO()
                    chunk.to_csv(csv_buffer, index=False, encoding='utf-8')
                    csv_data = csv_buffer.getvalue()
                    
                    # Google Driveã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                    media = MediaIoBaseUpload(
                        io.BytesIO(csv_data.encode('utf-8')),
                        mimetype='text/csv',
                        resumable=True
                    )
                    
                    file_metadata = {
                        'name': chunk_filename,
                        'parents': [self.folder_id],
                        'description': f'FusionPatentSearch data chunk {i+1}/{len(chunks)} - {len(chunk)} patents'
                    }
                    
                    file = self.drive_service.files().create(
                        body=file_metadata,
                        media_body=media,
                        fields='id'
                    ).execute()
                    
                    saved_files.append(file.get('id'))
                    st.info(f"âœ… ãƒ‘ãƒ¼ãƒˆ{i+1}/{len(chunks)}ä¿å­˜å®Œäº† ({len(chunk)}ä»¶)")
                    
                except Exception as e:
                    st.warning(f"ãƒ‘ãƒ¼ãƒˆ{i+1}ã®ä¿å­˜ã«å¤±æ•—: {str(e)}")
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            try:
                index_data = {
                    'total_records': len(df),
                    'total_chunks': len(chunks),
                    'chunk_size': chunk_size,
                    'mode': mode,
                    'timestamp': timestamp,
                    'file_ids': saved_files
                }
                
                index_filename = f"{base_filename}_index.json"
                index_content = json.dumps(index_data, indent=2)
                
                media = MediaIoBaseUpload(
                    io.BytesIO(index_content.encode('utf-8')),
                    mimetype='application/json',
                    resumable=True
                )
                
                file_metadata = {
                    'name': index_filename,
                    'parents': [self.folder_id],
                    'description': f'FusionPatentSearch index file - {len(df)} total patents'
                }
                
                index_file = self.drive_service.files().create(
                    body=file_metadata,
                    media_body=media,
                    fields='id'
                ).execute()
                
                st.success(f"ğŸ“‹ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {len(saved_files)}å€‹ã®ãƒ‘ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«")
                
            except Exception as e:
                st.warning(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¤±æ•—: {str(e)}")
            
            return saved_files
        
        else:
            # å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯é€šå¸¸ä¿å­˜
            csv_buffer = io.StringIO()
            df.to_csv(csv_buffer, index=False, encoding='utf-8')
            csv_data = csv_buffer.getvalue()
            
            media = MediaIoBaseUpload(
                io.BytesIO(csv_data.encode('utf-8')),
                mimetype='text/csv',
                resumable=True
            )
            
            file_metadata = {
                'name': f"{base_filename}.csv",
                'parents': [self.folder_id]
            }
            
            file = self.drive_service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id'
            ).execute()
            
            return file.get('id')
    
    def load_all_patent_data(self) -> pd.DataFrame:
        """ä¿å­˜ã•ã‚ŒãŸã™ã¹ã¦ã®ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        
        # ãƒ¡ãƒ¢ãƒªãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ
        if self.memory_data is not None and not self.memory_data.empty:
            return self.memory_data
        
        # Google Driveã‹ã‚‰èª­ã¿è¾¼ã¿
        try:
            files = self.list_patent_files()
            
            if not files:
                return pd.DataFrame()
            
            # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            latest_file = max(files, key=lambda x: x.get('createdTime', ''))
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            file_content = self.drive_service.files().get_media(fileId=latest_file['id']).execute()
            
            # CSVã¨ã—ã¦èª­ã¿è¾¼ã¿
            df = pd.read_csv(io.StringIO(file_content.decode('utf-8')))
            
            # æ—¥ä»˜åˆ—ã®å¤‰æ›
            if 'filing_date' in df.columns:
                df['filing_date'] = pd.to_datetime(df['filing_date'])
            if 'priority_date' in df.columns:
                df['priority_date'] = pd.to_datetime(df['priority_date'])
            
            return df
            
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()
    
    def list_patent_files(self) -> List[Dict]:
        """Google Driveã®ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—"""
        if not self.drive_service:
            return []
        
        try:
            query = f"'{self.folder_id}' in parents and name contains 'fusionpatentsearch' and mimeType='text/csv'"
            
            results = self.drive_service.files().list(
                q=query,
                fields='files(id, name, createdTime, size)',
                orderBy='createdTime desc'
            ).execute()
            
            return results.get('files', [])
            
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def collect_patents_to_memory(self) -> pd.DataFrame:
        """ãƒ¡ãƒ¢ãƒªå°‚ç”¨ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆGoogle Driveä½¿ç”¨ä¸å¯æ™‚ï¼‰"""
        
        # å…¨ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆï¼ˆå…¨ä»¶åé›†ï¼‰
        all_patents = []
        for company, patents in self.real_patents.items():
            all_patents.extend(patents)  # å„ç¤¾25ä»¶ã™ã¹ã¦ã‚’å–å¾—
        
        df = pd.DataFrame(all_patents)
        self.memory_data = df
        
        return df
    
    def get_collection_status(self) -> Dict[str, Any]:
        """åé›†çŠ¶æ³å–å¾—"""
        return {
            "memory_data_available": self.memory_data is not None,
            "memory_data_count": len(self.memory_data) if self.memory_data is not None else 0,
            "drive_service_available": self.drive_service is not None,
            "total_companies": len(self.real_patents),
            "total_potential_patents": sum(len(patents) for patents in self.real_patents.values()),
            "last_collected": self.collected_count
        }
    
    def generate_demo_data(self, count: int = 40) -> pd.DataFrame:
        """ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        demo_patents = []
        companies = ["Applied Materials", "Tokyo Electron", "Kyocera", "Lam Research"]
        
        for i in range(count):
            company = companies[i % len(companies)]
            
            patent = {
                'patent_number': f'US{10800000 + i}',
                'title': f'Advanced ESC Technology for {company} - Patent {i+1}',
                'assignee': company,
                'filing_date': pd.to_datetime(f'202{(i//10) + 0}-{(i%12)+1:02d}-15'),
                'filing_year': 2020 + (i // 10),
                'abstract': f'This patent describes advanced electrostatic chuck technology developed by {company}. The invention focuses on curved surface applications and wafer distortion control.',
                'inventors': [f'{company.split()[0]}Inventor{(i%3)+1}', f'{company.split()[0]}Inventor{(i%3)+2}'],
                'country': 'US',
                'technology_focus': 'electrostatic chuck',
                'citation_count': random.randint(5, 25)
            }
            
            demo_patents.append(patent)
        
        return pd.DataFrame(demo_patents)

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_collector():
    """åé›†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
    collector = CloudPatentDataCollector()
    
    print("=== CloudPatentDataCollector ãƒ†ã‚¹ãƒˆ ===")
    print(f"Google Drive API: {'âœ…' if collector.drive_service else 'âŒ'}")
    print(f"ãƒ•ã‚©ãƒ«ãƒ€ID: {collector.folder_id}")
    print(f"ç™»éŒ²ä¼æ¥­æ•°: {len(collector.real_patents)}")
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
    status = collector.get_collection_status()
    print("\n=== åé›†çŠ¶æ³ ===")
    for key, value in status.items():
        print(f"{key}: {value}")
    
    # ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    demo_df = collector.generate_demo_data(10)
    print(f"\n=== ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ ===")
    print(f"ç”Ÿæˆä»¶æ•°: {len(demo_df)}")
    print(f"ä¼æ¥­æ•°: {demo_df['assignee'].nunique()}")
    
    return collector

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_collector()
