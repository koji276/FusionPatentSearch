 #!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ›²é¢ESCç‰¹è¨±åˆ†æã‚·ã‚¹ãƒ†ãƒ 
Google Patents BigQueryã‚’ä½¿ç”¨ã—ã¦ä¸–ç•Œä¸­ã®æ›²é¢ESCé–¢é€£ç‰¹è¨±ã‚’åˆ†æ

ä½¿ç”¨æ–¹æ³•:
1. Google Cloud Projectã§BigQuery APIã‚’æœ‰åŠ¹åŒ–
2. èªè¨¼æƒ…å ±ã‚’è¨­å®š (gcloud auth application-default login)
3. python curved_esc_analyzer.py ã‚’å®Ÿè¡Œ

å‡ºåŠ›:
- curved_esc_patents.csv: å…¨ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿
- company_ranking.csv: ä¼æ¥­åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
- trend_analysis.csv: å¹´æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
- keyword_analysis.csv: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
"""

import pandas as pd
from google.cloud import bigquery
import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import Counter
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'sans-serif']

class CurvedESCPatentAnalyzer:
    def __init__(self):
        """BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            self.client = bigquery.Client()
            print("âœ“ BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šæˆåŠŸ")
        except Exception as e:
            print(f"âŒ BigQueryæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            print("Google Cloudèªè¨¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„: gcloud auth application-default login")
            exit(1)
    
    def search_curved_esc_patents(self):
        """ESCé–¢é€£ç‰¹è¨±ã‚’æ—¥è‹±ä¸¡è¨€èªã§æ¤œç´¢ - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä¼æ¥­ç‰¹åŒ–ç‰ˆ"""
        query = """
        SELECT DISTINCT
            p.publication_number,
            p.country_code,
            p.filing_date,
            p.publication_date,
            p.application_kind,
            COALESCE(title_en.text, title_ja.text, title_other.text) as title,
            COALESCE(abstract_en.text, abstract_ja.text, abstract_other.text) as abstract,
            p.assignee_harmonized as assignee,
            p.inventor_harmonized as inventor,
            p.cpc_at_publication as cpc_codes
        FROM `patents-public-data.patents.publications` p
        LEFT JOIN UNNEST(title_localized) as title_en ON title_en.language = 'en'
        LEFT JOIN UNNEST(title_localized) as title_ja ON title_ja.language = 'ja' 
        LEFT JOIN UNNEST(title_localized) as title_other ON title_other.language NOT IN ('en', 'ja')
        LEFT JOIN UNNEST(abstract_localized) as abstract_en ON abstract_en.language = 'en'
        LEFT JOIN UNNEST(abstract_localized) as abstract_ja ON abstract_ja.language = 'ja'
        LEFT JOIN UNNEST(abstract_localized) as abstract_other ON abstract_other.language NOT IN ('en', 'ja')
        WHERE (
            -- ESCé–¢é€£æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè‹±èªï¼‰
            (REGEXP_CONTAINS(LOWER(COALESCE(title_en.text, '')), r'electrostatic.*chuck|esc|curved.*chuck|flexible.*chuck|wafer.*chuck')
             OR REGEXP_CONTAINS(LOWER(COALESCE(abstract_en.text, '')), r'electrostatic.*chuck|esc|curved.*substrate|flexible.*substrate|wafer.*distortion|substrate.*warpage'))
            OR
            -- ESCé–¢é€£æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ—¥æœ¬èªï¼‰
            (REGEXP_CONTAINS(COALESCE(title_ja.text, ''), r'é™é›»ãƒãƒ£ãƒƒã‚¯|ESC|ã‚¦ã‚¨ãƒãƒãƒ£ãƒƒã‚¯|åŸºæ¿ãƒãƒ£ãƒƒã‚¯|æ›²é¢.*ãƒãƒ£ãƒƒã‚¯')
             OR REGEXP_CONTAINS(COALESCE(abstract_ja.text, ''), r'é™é›».*ãƒãƒ£ãƒƒã‚¯|ã‚¦ã‚¨ãƒ.*åã‚Š|åŸºæ¿.*æ­ª|ãƒãƒ£ãƒƒã‚¯.*å¸ç€|é™é›».*å¸ç€'))
            OR
            -- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä¼æ¥­ã§ã®å‡ºé¡˜
            (REGEXP_CONTAINS(UPPER(COALESCE(p.assignee_harmonized, '')), 
                r'SHINKO ELECTRIC|TOTO|SUMITOMO OSAKA CEMENT|KYOCERA|NGK|NTK CERATEC|TSUKUBA SEIKO|CREATIVE TECHNOLOGY|TOKYO ELECTRON|APPLIED MATERIALS|LAM RESEARCH|ENTEGRIS|FM INDUSTRIES|MICO|SEMCO|CALITECH|BEIJING U-PRECISION|æ–°å…‰é›»æ°—|ä½å‹å¤§é˜ªã‚»ãƒ¡ãƒ³ãƒˆ|äº¬ã‚»ãƒ©|æ—¥æœ¬ã‚¬ã‚¤ã‚·|ç­‘æ³¢ç²¾å·¥|æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³'))
        )
        AND p.filing_date >= '2010-01-01'
        AND p.filing_date <= '2024-12-31'
        ORDER BY p.filing_date DESC
        LIMIT 15000
        """
        
        print("ğŸ” ESCé–¢é€£ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ä¸­ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆä¼æ¥­é‡ç‚¹ï¼‰...")
        try:
            df = self.client.query(query).to_dataframe()
            print(f"âœ“ {len(df)}ä»¶ã®ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
            return df
        except Exception as e:
            print(f"âŒ ã‚¯ã‚¨ãƒªã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def normalize_company_names(self, df):
        """ä¼æ¥­åã®æ­£è¦åŒ– - ESCãƒ¡ãƒ¼ã‚«ãƒ¼ç‰¹åŒ–ç‰ˆ"""
        company_mapping = {
            # æ—¥æœ¬ä¼æ¥­
            'SHINKO ELECTRIC': ['æ–°å…‰é›»æ°—å·¥æ¥­', 'SHINKO ELECTRIC INDUSTRIES', 'Shinko Electric'],
            'TOTO': ['TOTO', 'TOTO LTD', 'ãƒˆãƒ¼ãƒˆãƒ¼'],
            'SUMITOMO OSAKA CEMENT': ['ä½å‹å¤§é˜ªã‚»ãƒ¡ãƒ³ãƒˆ', 'SUMITOMO OSAKA CEMENT CO'],
            'KYOCERA': ['Kyocera', 'äº¬ã‚»ãƒ©', 'KYOCERA CORPORATION'],
            'NGK INSULATORS': ['NGK', 'æ—¥æœ¬ã‚¬ã‚¤ã‚·', 'NGK INSULATORS LTD'],
            'NTK CERATEC': ['NTK CERATEC', 'NTKã‚»ãƒ©ãƒ†ãƒƒã‚¯', 'æ—¥æœ¬ç‰¹æ®Šé™¶æ¥­', 'NGK SPARK PLUG'],
            'TSUKUBA SEIKO': ['ç­‘æ³¢ç²¾å·¥', 'TSUKUBA SEIKO CO'],
            'CREATIVE TECHNOLOGY': ['ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼', 'CREATIVE TECHNOLOGY'],
            'TOKYO ELECTRON': ['Tokyo Electron', 'TEL', 'TOKYO ELECTRON LIMITED', 'æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³'],
            
            # æµ·å¤–ä¼æ¥­
            'APPLIED MATERIALS': ['Applied Materials', 'AMAT', 'APPLIED MATERIALS INC'],
            'LAM RESEARCH': ['Lam Research', 'LAM RESEARCH CORPORATION'],
            'ENTEGRIS': ['Entegris', 'ENTEGRIS INC'],
            'FM INDUSTRIES': ['FM Industries', 'FM INDUSTRIES INC'],  # æ—¥æœ¬ã‚¬ã‚¤ã‚·ãŒè²·å
            'MICO': ['MiCo', 'MICO CERAMICS', 'MICO CO'],
            'SEMCO ENGINEERING': ['SEMCO Engineering', 'SEMCO ENGINEERING SAS'],
            'CALITECH': ['Calitech', 'CALITECH CO'],
            'BEIJING U-PRECISION': ['Beijing U-Precision', 'U-PRECISION TECH', 'BEIJING U-PRECISION TECH'],
            
            # é–¢é€£ä¼æ¥­ï¼ˆæ¯”è¼ƒå¯¾è±¡ï¼‰
            'KLA': ['KLA-Tencor', 'KLA CORPORATION'],
            'HITACHI HIGH-TECH': ['Hitachi High-Tech', 'æ—¥ç«‹ãƒã‚¤ãƒ†ã‚¯'],
            'SCREEN': ['SCREEN Holdings', 'SCREEN SEMICONDUCTOR'],
            'ASML': ['ASML NETHERLANDS', 'ASML HOLDING']
        }
        
        df['normalized_assignee'] = df['assignee'].fillna('Unknown')
        
        for normalized, variants in company_mapping.items():
            for variant in variants:
                mask = df['normalized_assignee'].str.contains(variant, case=False, na=False)
                df.loc[mask, 'normalized_assignee'] = normalized
        
        return df
    
    def extract_keywords(self, text_series):
        """æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æŠ½å‡º"""
        if text_series.isna().all():
            return Counter()
        
        # è‹±èªæŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        en_keywords = [
            'curved', 'flexible', 'bendable', 'conformal', 'variable curvature',
            'electrostatic chuck', 'ESC', 'wafer distortion', 'substrate warpage',
            'temperature control', 'plasma confinement', 'ceramic', 'electrode',
            'dielectric', 'RF distribution', 'etch uniformity', 'clamping force'
        ]
        
        # æ—¥æœ¬èªæŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        ja_keywords = [
            'æ›²é¢', 'æ¹¾æ›²', 'å¯æ’“æ€§', 'ãƒ•ãƒ¬ã‚­ã‚·ãƒ–ãƒ«', 'é™é›»ãƒãƒ£ãƒƒã‚¯',
            'ã‚¦ã‚¨ãƒåã‚Š', 'åŸºæ¿æ­ªã¿', 'æ¸©åº¦åˆ¶å¾¡', 'å¯†ç€æ€§', 'å¸ç€åŠ›',
            'ã‚»ãƒ©ãƒŸãƒƒã‚¯', 'èª˜é›»ä½“', 'é›»æ¥µæ§‹é€ ', 'ãƒ—ãƒ©ã‚ºãƒ', 'ã‚¨ãƒƒãƒãƒ³ã‚°å‡ä¸€æ€§'
        ]
        
        all_text = ' '.join(text_series.fillna('').astype(str))
        keyword_counts = Counter()
        
        for keyword in en_keywords + ja_keywords:
            count = len(re.findall(keyword, all_text, re.IGNORECASE))
            if count > 0:
                keyword_counts[keyword] = count
        
        return keyword_counts
    
    def analyze_data(self, df):
        """ãƒ‡ãƒ¼ã‚¿åˆ†æå®Ÿè¡Œ"""
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’é–‹å§‹...")
        
        # åŸºæœ¬çµ±è¨ˆ
        total_patents = len(df)
        date_range = f"{df['filing_date'].min()} ï½ {df['filing_date'].max()}"
        unique_companies = df['normalized_assignee'].nunique()
        
        print(f"ğŸ“ˆ ç·ç‰¹è¨±æ•°: {total_patents}ä»¶")
        print(f"ğŸ“… å¯¾è±¡æœŸé–“: {date_range}")
        print(f"ğŸ¢ å‡ºé¡˜æ©Ÿé–¢æ•°: {unique_companies}æ©Ÿé–¢")
        
        # ä¼æ¥­åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        company_ranking = df['normalized_assignee'].value_counts().head(20)
        print(f"\nğŸ† ãƒˆãƒƒãƒ—ä¼æ¥­: {company_ranking.index[0]} ({company_ranking.iloc[0]}ä»¶)")
        
        # å¹´æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰
        df['filing_year'] = pd.to_datetime(df['filing_date']).dt.year
        yearly_trend = df.groupby('filing_year').size()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        title_keywords = self.extract_keywords(df['title'])
        abstract_keywords = self.extract_keywords(df['abstract'])
        
        return {
            'total_patents': total_patents,
            'company_ranking': company_ranking,
            'yearly_trend': yearly_trend,
            'title_keywords': title_keywords,
            'abstract_keywords': abstract_keywords,
            'unique_companies': unique_companies
        }
    
    def create_visualizations(self, df, analysis_results):
        """å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ã®ä½œæˆ"""
        print("\nğŸ“Š å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ã‚’ä½œæˆä¸­...")
        
        # ä¼æ¥­åˆ¥å‡ºé¡˜ä»¶æ•° (Top 15)
        plt.figure(figsize=(12, 8))
        top_companies = analysis_results['company_ranking'].head(15)
        ax1 = plt.subplot(2, 2, 1)
        top_companies.plot(kind='barh', ax=ax1)
        plt.title('Top 15 Companies - Curved ESC Patents', fontsize=12, fontweight='bold')
        plt.xlabel('Number of Patents')
        plt.tight_layout()
        
        # å¹´æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰
        ax2 = plt.subplot(2, 2, 2)
        analysis_results['yearly_trend'].plot(kind='line', marker='o', ax=ax2)
        plt.title('Yearly Filing Trend', fontsize=12, fontweight='bold')
        plt.xlabel('Year')
        plt.ylabel('Number of Patents')
        plt.grid(True, alpha=0.3)
        
        # å›½åˆ¥åˆ†å¸ƒ
        ax3 = plt.subplot(2, 2, 3)
        country_dist = df['country_code'].value_counts().head(10)
        country_dist.plot(kind='pie', ax=ax3, autopct='%1.1f%%')
        plt.title('Patent Distribution by Country', fontsize=12, fontweight='bold')
        
        # æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (Top 10)
        ax4 = plt.subplot(2, 2, 4)
        top_keywords = Counter(analysis_results['title_keywords']) + Counter(analysis_results['abstract_keywords'])
        if top_keywords:
            keywords_df = pd.Series(dict(top_keywords.most_common(10)))
            keywords_df.plot(kind='barh', ax=ax4)
            plt.title('Top Technology Keywords', fontsize=12, fontweight='bold')
            plt.xlabel('Frequency')
        
        plt.tight_layout()
        plt.savefig('curved_esc_analysis.png', dpi=300, bbox_inches='tight')
        print("âœ“ ã‚°ãƒ©ãƒ•ã‚’ 'curved_esc_analysis.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        # è©³ç´°ãªå¹´æ¬¡ãƒ»ä¼æ¥­åˆ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        plt.figure(figsize=(14, 8))
        
        # ä¸»è¦ä¼æ¥­ã®å¹´æ¬¡å‡ºé¡˜æ¨ç§»
        top_10_companies = analysis_results['company_ranking'].head(10).index
        company_year_data = df[df['normalized_assignee'].isin(top_10_companies)]
        heatmap_data = company_year_data.pivot_table(
            index='normalized_assignee', 
            columns='filing_year', 
            values='publication_number', 
            aggfunc='count', 
            fill_value=0
        )
        
        sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='YlOrRd', 
                   cbar_kws={'label': 'Number of Patents'})
        plt.title('Patent Filing Heatmap: Top Companies by Year', 
                 fontsize=14, fontweight='bold')
        plt.xlabel('Filing Year')
        plt.ylabel('Company')
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        
        plt.tight_layout()
        plt.savefig('company_year_heatmap.png', dpi=300, bbox_inches='tight')
        print("âœ“ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ 'company_year_heatmap.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
    def save_results(self, df, analysis_results):
        """çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        print("\nğŸ’¾ çµæœã‚’ä¿å­˜ä¸­...")
        
        # å…¨ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿
        df.to_csv('curved_esc_patents.csv', index=False, encoding='utf-8-sig')
        print("âœ“ curved_esc_patents.csv")
        
        # ä¼æ¥­åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        analysis_results['company_ranking'].to_csv('company_ranking.csv', 
                                                  header=['Patent_Count'], encoding='utf-8-sig')
        print("âœ“ company_ranking.csv")
        
        # å¹´æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰
        analysis_results['yearly_trend'].to_csv('yearly_trend.csv', 
                                               header=['Patent_Count'], encoding='utf-8-sig')
        print("âœ“ yearly_trend.csv")
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        combined_keywords = Counter(analysis_results['title_keywords']) + Counter(analysis_results['abstract_keywords'])
        pd.Series(dict(combined_keywords.most_common(50))).to_csv('keyword_analysis.csv', 
                                                                  header=['Frequency'], encoding='utf-8-sig')
        print("âœ“ keyword_analysis.csv")
        
        # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
        with open('analysis_summary.txt', 'w', encoding='utf-8') as f:
            f.write("=== æ›²é¢ESCç‰¹è¨±åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ===\n")
            f.write(f"åˆ†ææ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"ç·ç‰¹è¨±æ•°: {analysis_results['total_patents']:,}ä»¶\n")
            f.write(f"å‡ºé¡˜æ©Ÿé–¢æ•°: {analysis_results['unique_companies']:,}æ©Ÿé–¢\n\n")
            f.write("=== ãƒˆãƒƒãƒ—10ä¼æ¥­ ===\n")
            for i, (company, count) in enumerate(analysis_results['company_ranking'].head(10).items(), 1):
                f.write(f"{i:2d}. {company}: {count:,}ä»¶\n")
            f.write("\n=== ä¸»è¦æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ===\n")
            combined_keywords = Counter(analysis_results['title_keywords']) + Counter(analysis_results['abstract_keywords'])
            for i, (keyword, count) in enumerate(combined_keywords.most_common(20), 1):
                f.write(f"{i:2d}. {keyword}: {count:,}å›\n")
        
        print("âœ“ analysis_summary.txt")
        print(f"\nğŸ‰ åˆ†æå®Œäº†ï¼{analysis_results['total_patents']}ä»¶ã®æ›²é¢ESCé–¢é€£ç‰¹è¨±ã‚’åˆ†æã—ã¾ã—ãŸã€‚")
    
    def run_analysis(self):
        """ãƒ¡ã‚¤ãƒ³åˆ†æãƒ—ãƒ­ã‚»ã‚¹ã®å®Ÿè¡Œ"""
        print("ğŸš€ æ›²é¢ESCç‰¹è¨±åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã™...")
        print("=" * 50)
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        df = self.search_curved_esc_patents()
        if df.empty:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
        df = self.normalize_company_names(df)
        
        # åˆ†æå®Ÿè¡Œ
        analysis_results = self.analyze_data(df)
        
        # å¯è¦–åŒ–
        self.create_visualizations(df, analysis_results)
        
        # çµæœä¿å­˜
        self.save_results(df, analysis_results)

if __name__ == "__main__":
    analyzer = CurvedESCPatentAnalyzer()
    analyzer.run_analysis()
