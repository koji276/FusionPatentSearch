 #!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ›²é¢ESCç‰¹è¨± é«˜åº¦åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã®åˆ†æã¨æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰è©³ç´°åˆ†æ

ä½¿ç”¨æ–¹æ³•:
python advanced_analyzer.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import re
from collections import Counter, defaultdict
import networkx as nx
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

class AdvancedPatentAnalyzer:
    def __init__(self, patent_data_file='curved_esc_patents.csv'):
        """ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        try:
            self.df = pd.read_csv(patent_data_file, encoding='utf-8-sig')
            print(f"âœ“ {len(self.df)}ä»¶ã®ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except FileNotFoundError:
            print("âŒ ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«curved_esc_analyzer.pyã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            exit(1)
    
    def classify_organizations(self):
        """çµ„ç¹”ã‚¿ã‚¤ãƒ—ã®åˆ†é¡ï¼ˆä¼æ¥­/å¤§å­¦/ç ”ç©¶æ©Ÿé–¢ï¼‰"""
        print("\nğŸ›ï¸ çµ„ç¹”ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡ä¸­...")
        
        # å¤§å­¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        university_keywords = [
            'UNIVERSITY', 'UNIV', 'COLLEGE', 'INSTITUTE OF TECHNOLOGY',
            'TECH UNIVERSITY', 'STATE UNIVERSITY', 'NATIONAL UNIVERSITY',
            'å¤§å­¦', 'å·¥æ¥­å¤§å­¦', 'æŠ€è¡“å¤§å­¦', 'ç§‘å­¦æŠ€è¡“å¤§å­¦', 'KAIST', 'POSTECH'
        ]
        
        # ç ”ç©¶æ©Ÿé–¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰  
        research_keywords = [
            'RESEARCH', 'INSTITUTE', 'LABORATORY', 'LAB', 'CENTER',
            'FOUNDATION', 'AGENCY', 'ORGANIZATION', 'COUNCIL',
            'ç ”ç©¶æ‰€', 'ç ”ç©¶æ©Ÿæ§‹', 'ç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼', 'æŠ€è¡“ç ”ç©¶çµ„åˆ', 'ç”£ç·ç ”', 'AIST'
        ]
        
        def classify_org(assignee):
            if pd.isna(assignee):
                return 'Unknown'
            
            assignee_upper = assignee.upper()
            
            # å¤§å­¦åˆ¤å®š
            for keyword in university_keywords:
                if keyword in assignee_upper:
                    return 'University'
            
            # ç ”ç©¶æ©Ÿé–¢åˆ¤å®š
            for keyword in research_keywords:
                if keyword in assignee_upper:
                    return 'Research Institute'
            
            return 'Company'
        
        self.df['org_type'] = self.df['normalized_assignee'].apply(classify_org)
        
        # çµ±è¨ˆè¡¨ç¤º
        org_stats = self.df['org_type'].value_counts()
        print("ğŸ“Š çµ„ç¹”ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ:")
        for org_type, count in org_stats.items():
            percentage = count / len(self.df) * 100
            print(f"   {org_type}: {count}ä»¶ ({percentage:.1f}%)")
        
        return org_stats
    
    def university_ranking_analysis(self):
        """å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ"""
        print("\nğŸ“ å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ...")
        
        academic_orgs = self.df[self.df['org_type'].isin(['University', 'Research Institute'])]
        
        if len(academic_orgs) == 0:
            print("ğŸ” å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã®ç‰¹è¨±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return pd.DataFrame(), pd.DataFrame()
        
        # å¤§å­¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        university_ranking = academic_orgs[academic_orgs['org_type'] == 'University']['normalized_assignee'].value_counts()
        
        # ç ”ç©¶æ©Ÿé–¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°  
        research_ranking = academic_orgs[academic_orgs['org_type'] == 'Research Institute']['normalized_assignee'].value_counts()
        
        print(f"ğŸ† ãƒˆãƒƒãƒ—å¤§å­¦ (Top 10):")
        for i, (univ, count) in enumerate(university_ranking.head(10).items(), 1):
            print(f"   {i:2d}. {univ}: {count}ä»¶")
        
        print(f"\nğŸ”¬ ãƒˆãƒƒãƒ—ç ”ç©¶æ©Ÿé–¢ (Top 10):")
        for i, (inst, count) in enumerate(research_ranking.head(10).items(), 1):
            print(f"   {i:2d}. {inst}: {count}ä»¶")
        
        return university_ranking, research_ranking
    
    def technology_trend_analysis(self):
        """è©³ç´°æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        print("\nğŸ“ˆ æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰è©³ç´°åˆ†æä¸­...")
        
        # å¹´åº¦ãƒ‡ãƒ¼ã‚¿æº–å‚™
        self.df['filing_year'] = pd.to_datetime(self.df['filing_date']).dt.year
        
        # æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†é¡
        tech_categories = {
            'Material': ['ceramic', 'dielectric', 'coating', 'polymer', 'silicon', 'ã‚»ãƒ©ãƒŸãƒƒã‚¯', 'èª˜é›»ä½“'],
            'Control': ['temperature', 'thermal', 'control', 'feedback', 'sensor', 'æ¸©åº¦åˆ¶å¾¡', 'åˆ¶å¾¡'],
            'Structure': ['electrode', 'chuck', 'clamp', 'surface', 'geometry', 'é›»æ¥µ', 'ãƒãƒ£ãƒƒã‚¯'],
            'Process': ['plasma', 'etching', 'deposition', 'CVD', 'sputtering', 'ãƒ—ãƒ©ã‚ºãƒ', 'ã‚¨ãƒƒãƒãƒ³ã‚°'],
            'Measurement': ['monitoring', 'detection', 'measurement', 'sensing', 'æ¸¬å®š', 'ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°']
        }
        
        # å„æŠ€è¡“ã‚«ãƒ†ã‚´ãƒªã®å¹´æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰
        tech_trends = {}
        
        for category, keywords in tech_categories.items():
            yearly_counts = {}
            
            for year in range(2015, 2025):
                year_data = self.df[self.df['filing_year'] == year]
                count = 0
                
                for _, row in year_data.iterrows():
                    text = str(row['title']) + ' ' + str(row['abstract'])
                    for keyword in keywords:
                        if keyword.lower() in text.lower():
                            count += 1
                            break  # 1ä»¶ã«ã¤ã1å›ã®ã¿ã‚«ã‚¦ãƒ³ãƒˆ
                
                yearly_counts[year] = count
            
            tech_trends[category] = yearly_counts
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
        tech_trend_df = pd.DataFrame(tech_trends)
        
        print("ğŸ“Š æŠ€è¡“åˆ†é‡åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ (2015-2024):")
        for category in tech_categories.keys():
            total = sum(tech_trends[category].values())
            print(f"   {category}: {total}ä»¶")
        
        return tech_trend_df
    
    def collaboration_network_analysis(self):
        """å…±åŒç ”ç©¶ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ"""
        print("\nğŸ¤ å…±åŒç ”ç©¶ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æä¸­...")
        
        # è¤‡æ•°å‡ºé¡˜äººãŒã„ã‚‹ç‰¹è¨±ã‚’æŠ½å‡º
        collaboration_patents = []
        
        for _, row in self.df.iterrows():
            if pd.notna(row['assignee']) and ';' in str(row['assignee']):
                assignees = [a.strip() for a in str(row['assignee']).split(';')]
                if len(assignees) > 1:
                    collaboration_patents.append({
                        'patent_id': row['publication_number'],
                        'assignees': assignees,
                        'filing_year': row.get('filing_year', 0)
                    })
        
        print(f"ğŸ” å…±åŒå‡ºé¡˜ç‰¹è¨±: {len(collaboration_patents)}ä»¶ç™ºè¦‹")
        
        # å…±åŒç ”ç©¶ãƒšã‚¢ã®æŠ½å‡º
        collaboration_pairs = Counter()
        
        for patent in collaboration_patents:
            assignees = patent['assignees']
            for i in range(len(assignees)):
                for j in range(i+1, len(assignees)):
                    pair = tuple(sorted([assignees[i], assignees[j]]))
                    collaboration_pairs[pair] += 1
        
        # ä¸Šä½å…±åŒç ”ç©¶ãƒšã‚¢
        print("\nğŸ† é »å‡ºå…±åŒç ”ç©¶ãƒšã‚¢ (Top 10):")
        for i, ((org1, org2), count) in enumerate(collaboration_pairs.most_common(10), 1):
            print(f"   {i:2d}. {org1} Ã— {org2}: {count}ä»¶")
        
        return collaboration_patents, collaboration_pairs
    
    def emerging_technology_detection(self):
        """æ–°èˆˆæŠ€è¡“ã®æ¤œå‡º"""
        print("\nğŸš€ æ–°èˆˆæŠ€è¡“æ¤œå‡ºåˆ†æä¸­...")
        
        # å‰æœŸï¼ˆ2015-2019ï¼‰ã¨å¾ŒæœŸï¼ˆ2020-2024ï¼‰ã§æ¯”è¼ƒ
        early_period = self.df[self.df['filing_year'].between(2015, 2019)]
        recent_period = self.df[self.df['filing_year'].between(2020, 2024)]
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        early_texts = (early_period['title'].fillna('') + ' ' + early_period['abstract'].fillna('')).tolist()
        recent_texts = (recent_period['title'].fillna('') + ' ' + recent_period['abstract'].fillna('')).tolist()
        
        if len(early_texts) == 0 or len(recent_texts) == 0:
            print("âš ï¸ æ¯”è¼ƒç”¨ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return
        
        # TF-IDFåˆ†æ
        vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words='english',
            ngram_range=(1, 2),
            min_df=2
        )
        
        # å‰æœŸã®TF-IDF
        early_tfidf = vectorizer.fit_transform(early_texts)
        early_scores = early_tfidf.mean(axis=0).A1
        
        # å¾ŒæœŸã®TF-IDF  
        recent_tfidf = vectorizer.transform(recent_texts)
        recent_scores = recent_tfidf.mean(axis=0).A1
        
        # ã‚¹ã‚³ã‚¢å·®åˆ†è¨ˆç®—
        feature_names = vectorizer.get_feature_names_out()
        score_diff = recent_scores - early_scores
        
        # æ–°èˆˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¾ŒæœŸã§æ€¥ä¸Šæ˜‡ï¼‰
        emerging_indices = np.argsort(score_diff)[-20:]
        emerging_keywords = [(feature_names[i], score_diff[i]) for i in emerging_indices[::-1]]
        
        print("ğŸ”¥ æ–°èˆˆæŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (Top 15):")
        for i, (keyword, score) in enumerate(emerging_keywords[:15], 1):
            print(f"   {i:2d}. {keyword}: +{score:.4f}")
        
        return emerging_keywords
    
    def create_advanced_visualizations(self, org_stats, tech_trend_df, university_ranking, research_ranking):
        """é«˜åº¦ãªå¯è¦–åŒ–ã®ä½œæˆ"""
        print("\nğŸ¨ é«˜åº¦å¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
        
        # å›³å…¨ä½“ã®è¨­å®š
        fig = plt.figure(figsize=(20, 16))
        
        # 1. çµ„ç¹”ã‚¿ã‚¤ãƒ—åˆ¥åˆ†å¸ƒ
        ax1 = plt.subplot(3, 3, 1)
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
        wedges, texts, autotexts = ax1.pie(org_stats.values, labels=org_stats.index, 
                                          autopct='%1.1f%%', colors=colors)
        ax1.set_title('Organization Type Distribution', fontweight='bold', fontsize=12)
        
        # 2. æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰æ¨ç§»
        ax2 = plt.subplot(3, 3, 2)
        for column in tech_trend_df.columns:
            ax2.plot(tech_trend_df.index, tech_trend_df[column], marker='o', label=column, linewidth=2)
        ax2.set_title('Technology Trend by Category', fontweight='bold', fontsize=12)
        ax2.set_xlabel('Year')
        ax2.set_ylabel('Number of Patents')
        ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax2.grid(True, alpha=0.3)
        
        # 3. å¤§å­¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° (Top 10)
        ax3 = plt.subplot(3, 3, 3)
        if len(university_ranking) > 0:
            top_unis = university_ranking.head(10)
            ax3.barh(range(len(top_unis)), top_unis.values, color='skyblue')
            ax3.set_yticks(range(len(top_unis)))
            ax3.set_yticklabels([name[:20] + '...' if len(name) > 20 else name for name in top_unis.index])
            ax3.set_title('Top Universities', fontweight='bold', fontsize=12)
            ax3.set_xlabel('Number of Patents')
        
        # 4. ç ”ç©¶æ©Ÿé–¢ãƒ©ãƒ³ã‚­ãƒ³ã‚° (Top 10)
        ax4 = plt.subplot(3, 3, 4)
        if len(research_ranking) > 0:
            top_research = research_ranking.head(10)
            ax4.barh(range(len(top_research)), top_research.values, color='lightcoral')
            ax4.set_yticks(range(len(top_research)))
            ax4.set_yticklabels([name[:20] + '...' if len(name) > 20 else name for name in top_research.index])
            ax4.set_title('Top Research Institutes', fontweight='bold', fontsize=12)
            ax4.set_xlabel('Number of Patents')
        
        # 5. ä¼æ¥­ vs å­¦è¡“æ©Ÿé–¢ã®å¹´æ¬¡æ¯”è¼ƒ
        ax5 = plt.subplot(3, 3, 5)
        yearly_org_data = self.df.groupby(['filing_year', 'org_type']).size().unstack(fill_value=0)
        
        if 'Company' in yearly_org_data.columns:
            ax5.plot(yearly_org_data.index, yearly_org_data['Company'], 
                    marker='s', label='Company', linewidth=3, markersize=6)
        
        academic_patents = yearly_org_data.get('University', pd.Series(0)) + yearly_org_data.get('Research Institute', pd.Series(0))
        if len(academic_patents) > 0:
            ax5.plot(yearly_org_data.index, academic_patents, 
                    marker='^', label='Academic', linewidth=3, markersize=6)
        
        ax5.set_title('Company vs Academic Patents Trend', fontweight='bold', fontsize=12)
        ax5.set_xlabel('Year')
        ax5.set_ylabel('Number of Patents')
        ax5.legend()
        ax5.grid(True, alpha=0.3)
        
        # 6-9. æŠ€è¡“ã‚«ãƒ†ã‚´ãƒªåˆ¥å€‹åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰
        tech_categories = tech_trend_df.columns[:4]  # ä¸Šä½4ã‚«ãƒ†ã‚´ãƒª
        for i, category in enumerate(tech_categories):
            ax = plt.subplot(3, 3, 6+i)
            ax.bar(tech_trend_df.index, tech_trend_df[category], alpha=0.7, color=f'C{i}')
            ax.set_title(f'{category} Technology Trend', fontweight='bold', fontsize=10)
            ax.set_xlabel('Year')
            ax.set_ylabel('Patents')
            ax.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.savefig('advanced_analysis.png', dpi=300, bbox_inches='tight')
        print("âœ“ é«˜åº¦åˆ†æã‚°ãƒ©ãƒ•ã‚’ 'advanced_analysis.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        # è¿½åŠ : ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ
        self.create_wordcloud()
    
    def create_wordcloud(self):
        """æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ"""
        print("â˜ï¸ ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”Ÿæˆä¸­...")
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        all_text = ' '.join(self.df['title'].fillna('') + ' ' + self.df['abstract'].fillna(''))
        
        # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰å®šç¾©
        stop_words = {
            'method', 'system', 'apparatus', 'device', 'means', 'provided', 'including',
            'comprising', 'having', 'using', 'according', 'invention', 'present',
            'embodiment', 'example', 'first', 'second', 'third', 'one', 'two', 'three'
        }
        
        # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ
        wordcloud = WordCloud(
            width=1200, height=800,
            background_color='white',
            stopwords=stop_words,
            max_words=100,
            colormap='viridis',
            font_path=None  # ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆä½¿ç”¨
        ).generate(all_text)
        
        plt.figure(figsize=(15, 10))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        plt.title('Curved ESC Technology Keywords', fontsize=20, fontweight='bold', pad=20)
        plt.tight_layout()
        plt.savefig('technology_wordcloud.png', dpi=300, bbox_inches='tight')
        print("âœ“ ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ 'technology_wordcloud.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def generate_comprehensive_report(self, org_stats, university_ranking, research_ranking, 
                                    emerging_keywords, collaboration_pairs):
        """åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        print("\nğŸ“„ åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        
        with open('comprehensive_analysis_report.txt', 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("æ›²é¢ESCç‰¹è¨± åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write("=" * 80 + "\n")
            f.write(f"åˆ†ææ—¥æ™‚: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"åˆ†æå¯¾è±¡: {len(self.df):,}ä»¶ã®ç‰¹è¨±\n")
            f.write(f"å¯¾è±¡æœŸé–“: {self.df['filing_date'].min()} ï½ {self.df['filing_date'].max()}\n\n")
            
            # çµ„ç¹”åˆ†æ
            f.write("ã€çµ„ç¹”ã‚¿ã‚¤ãƒ—åˆ¥åˆ†æã€‘\n")
            f.write("-" * 40 + "\n")
            total_patents = len(self.df)
            for org_type, count in org_stats.items():
                percentage = count / total_patents * 100
                f.write(f"{org_type:18s}: {count:6,}ä»¶ ({percentage:5.1f}%)\n")
            
            # å¤§å­¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            f.write(f"\nã€å¤§å­¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 15ã€‘\n")
            f.write("-" * 40 + "\n")
            for i, (univ, count) in enumerate(university_ranking.head(15).items(), 1):
                f.write(f"{i:2d}. {univ:<40s}: {count:3,}ä»¶\n")
            
            # ç ”ç©¶æ©Ÿé–¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            f.write(f"\nã€ç ”ç©¶æ©Ÿé–¢ãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 15ã€‘\n")
            f.write("-" * 40 + "\n")
            for i, (inst, count) in enumerate(research_ranking.head(15).items(), 1):
                f.write(f"{i:2d}. {inst:<40s}: {count:3,}ä»¶\n")
            
            # æ–°èˆˆæŠ€è¡“
            f.write(f"\nã€æ–°èˆˆæŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ Top 20ã€‘\n")
            f.write("-" * 40 + "\n")
            for i, (keyword, score) in enumerate(emerging_keywords[:20], 1):
                f.write(f"{i:2d}. {keyword:<30s}: +{score:.4f}\n")
            
            # å…±åŒç ”ç©¶
            f.write(f"\nã€ä¸»è¦å…±åŒç ”ç©¶ãƒšã‚¢ Top 15ã€‘\n")
            f.write("-" * 40 + "\n")
            for i, ((org1, org2), count) in enumerate(collaboration_pairs.most_common(15), 1):
                f.write(f"{i:2d}. {org1} Ã— {org2}: {count}ä»¶\n")
            
            # å¹´æ¬¡çµ±è¨ˆ
            yearly_stats = self.df.groupby('filing_year').size()
            f.write(f"\nã€å¹´æ¬¡å‡ºé¡˜çµ±è¨ˆã€‘\n")
            f.write("-" * 40 + "\n")
            for year, count in yearly_stats.items():
                f.write(f"{year}: {count:,}ä»¶\n")
        
        print("âœ“ åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ 'comprehensive_analysis_report.txt' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def run_advanced_analysis(self):
        """é«˜åº¦åˆ†æã®å®Ÿè¡Œ"""
        print("ğŸ”¬ é«˜åº¦ç‰¹è¨±åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
        print("=" * 60)
        
        # 1. çµ„ç¹”åˆ†é¡
        org_stats = self.classify_organizations()
        
        # 2. å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        university_ranking, research_ranking = self.university_ranking_analysis()
        
        # 3. æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        tech_trend_df = self.technology_trend_analysis()
        
        # 4. å…±åŒç ”ç©¶ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        collaboration_patents, collaboration_pairs = self.collaboration_network_analysis()
        
        # 5. æ–°èˆˆæŠ€è¡“æ¤œå‡º
        emerging_keywords = self.emerging_technology_detection()
        
        # 6. é«˜åº¦å¯è¦–åŒ–
        self.create_advanced_visualizations(org_stats, tech_trend_df, university_ranking, research_ranking)
        
        # 7. åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_comprehensive_report(org_stats, university_ranking, research_ranking, 
                                         emerging_keywords, collaboration_pairs)
        
        print("\nğŸ‰ é«˜åº¦åˆ†æå®Œäº†ï¼è©³ç´°ãªåˆ†æçµæœãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        print("\nğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
        print("   - advanced_analysis.png (é«˜åº¦åˆ†æã‚°ãƒ©ãƒ•)")
        print("   - technology_wordcloud.png (æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é›²)")  
        print("   - comprehensive_analysis_report.txt (åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆ)")

if __name__ == "__main__":
    analyzer = AdvancedPatentAnalyzer()
    analyzer.run_advanced_analysis()
